# -*- coding: utf-8 -*-
"""1.2 Half Space classifier implemented using Perceptron Algorithm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bMazHGG27KZEDKKQmjSbBcajBynuFGRK
"""

from sklearn.preprocessing import MinMaxScaler
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score


# Loading CSV
data = pd.read_csv("/content/Prostate_Cancer.csv")
data.diagnosis_result = [1 if each == "M" else -1 for each in data.diagnosis_result]
print(data.head())


X = data.drop("diagnosis_result", axis=1)
Y = data["diagnosis_result"]
mnscaler = MinMaxScaler()
X = mnscaler.fit_transform(X)
X = pd.DataFrame(X, columns=data.drop("diagnosis_result", axis=1).columns)
X_train, X_test, Y_train, Y_test = train_test_split(
    X, Y, test_size=0.1, random_state=20)


class Perceptron:

    def __init__(self,learning_rate=0.01, n_iters=1000):
        self.lr = learning_rate
        self.n_iters = n_iters
        self.activation_func = self._unit_step_func
        self.weights = None
        self.bias = None

    def fit(self, X, y):
        n_samples, n_features = X.shape

        # init parameters
        self.weights = np.zeros(n_features)
        self.bias = 0
        print(y.shape)
        y_ = np.array([1 if i > 0 else 0 for i in y])

        for _ in range(self.n_iters):
            
            for idx, x_i in enumerate(X):

               
                
                linear_output = np.dot(x_i, self.weights) + self.bias
                y_predicted = self.activation_func(linear_output)
                
                # Perceptron update rule
                update =  self.lr*(y_[idx] - y_predicted)

                self.weights += update * x_i
                self.bias += update

    def predict(self, X):
        linear_output = np.dot(X, self.weights) + self.bias
        y_predicted = self.activation_func(linear_output)
        return y_predicted

    def _unit_step_func(self, x):
        return np.where(x>=0, 1, 0)


perceptron = Perceptron()



wt_matrix = perceptron.fit(X_train.to_numpy(), Y_train.to_numpy())

#making predictions on test data
Y_pred_test = perceptron.predict(X_test)

#checking the accuracy of the model
print(f"Accuracy = {accuracy_score(Y_pred_test, Y_test)}")

# using LogisticRegression from sklearn
from sklearn import linear_model
logreg = linear_model.LogisticRegression(random_state = 42,max_iter= 350)
print("Accuracy using package : {} ".format(logreg.fit(X_train, Y_train).score(X_test, Y_test)))