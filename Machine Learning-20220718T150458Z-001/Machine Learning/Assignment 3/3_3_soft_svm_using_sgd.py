# -*- coding: utf-8 -*-
"""3.3 Soft SVM using SGD.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MHIqq4kGFrkoX9wNPCNq4F6RBpgSfI1J
"""

import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

import matplotlib.pyplot as plt


df = pd.read_csv("dataset.csv")
print(df.shape)
df.head()

df = df.drop(["date", "time", "username"], axis=1)
df.head()

print(df.describe())
data = df.values
X = data[:, 1:]
y = data[:, 0]  
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Scale the data to be between -1 and 1
scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
from sklearn.linear_model import SGDClassifier
model = SGDClassifier(loss="hinge", penalty="l2")

model.fit(X_train, y_train)

print(model.score(X_test, y_test))

n_iters = [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 1000]
scores = []
for n_iter in n_iters:
    model = SGDClassifier(loss="hinge", penalty="l2", max_iter=n_iter)
    model.fit(X_train, y_train)
    scores.append(model.score(X_test, y_test))
  
plt.title("Effect of n_iter")
plt.xlabel("n_iter")
plt.ylabel("score")
plt.plot(n_iters, scores)